{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from time import sleep\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import unicodedata\n",
    "import json\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "import pprint as pprint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import scipy.stats as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('trigger_warning_tweets.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are nulls\n",
    "Drop rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                      0\n",
       "tweet                      1\n",
       "trigger_scene              0\n",
       "cleaned_text               3\n",
       "stemmed_text               3\n",
       "lemmatized_text            3\n",
       "lemmatized_no_stopwords    7\n",
       "stemmed_no_stopwords       5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                      0\n",
       "tweet                      0\n",
       "trigger_scene              0\n",
       "cleaned_text               0\n",
       "stemmed_text               0\n",
       "lemmatized_text            0\n",
       "lemmatized_no_stopwords    0\n",
       "stemmed_no_stopwords       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the matrix of tfidf values for bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(2,2))\n",
    "X = tfidf.fit_transform(df.lemmatized_no_stopwords)\n",
    "y = df.trigger_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>007 novel</th>\n",
       "      <th>00s version</th>\n",
       "      <th>010 recommend</th>\n",
       "      <th>02 second</th>\n",
       "      <th>03 2018</th>\n",
       "      <th>03 snes</th>\n",
       "      <th>0539 debbie</th>\n",
       "      <th>06 tony</th>\n",
       "      <th>08 back</th>\n",
       "      <th>0806 email</th>\n",
       "      <th>...</th>\n",
       "      <th>zone pretty</th>\n",
       "      <th>zone right</th>\n",
       "      <th>zone start</th>\n",
       "      <th>zooey deschanel</th>\n",
       "      <th>zoolander acenterforants</th>\n",
       "      <th>zootopia going</th>\n",
       "      <th>zorx gamepad</th>\n",
       "      <th>zu belegen</th>\n",
       "      <th>zu perk</th>\n",
       "      <th>zune glengarry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29293 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   007 novel  00s version  010 recommend  02 second  03 2018  03 snes  \\\n",
       "0        0.0          0.0            0.0        0.0      0.0      0.0   \n",
       "1        0.0          0.0            0.0        0.0      0.0      0.0   \n",
       "2        0.0          0.0            0.0        0.0      0.0      0.0   \n",
       "3        0.0          0.0            0.0        0.0      0.0      0.0   \n",
       "4        0.0          0.0            0.0        0.0      0.0      0.0   \n",
       "5        0.0          0.0            0.0        0.0      0.0      0.0   \n",
       "6        0.0          0.0            0.0        0.0      0.0      0.0   \n",
       "7        0.0          0.0            0.0        0.0      0.0      0.0   \n",
       "8        0.0          0.0            0.0        0.0      0.0      0.0   \n",
       "9        0.0          0.0            0.0        0.0      0.0      0.0   \n",
       "\n",
       "   0539 debbie  06 tony  08 back  0806 email  ...  zone pretty  zone right  \\\n",
       "0          0.0      0.0      0.0         0.0  ...          0.0         0.0   \n",
       "1          0.0      0.0      0.0         0.0  ...          0.0         0.0   \n",
       "2          0.0      0.0      0.0         0.0  ...          0.0         0.0   \n",
       "3          0.0      0.0      0.0         0.0  ...          0.0         0.0   \n",
       "4          0.0      0.0      0.0         0.0  ...          0.0         0.0   \n",
       "5          0.0      0.0      0.0         0.0  ...          0.0         0.0   \n",
       "6          0.0      0.0      0.0         0.0  ...          0.0         0.0   \n",
       "7          0.0      0.0      0.0         0.0  ...          0.0         0.0   \n",
       "8          0.0      0.0      0.0         0.0  ...          0.0         0.0   \n",
       "9          0.0      0.0      0.0         0.0  ...          0.0         0.0   \n",
       "\n",
       "   zone start  zooey deschanel  zoolander acenterforants  zootopia going  \\\n",
       "0         0.0              0.0                       0.0             0.0   \n",
       "1         0.0              0.0                       0.0             0.0   \n",
       "2         0.0              0.0                       0.0             0.0   \n",
       "3         0.0              0.0                       0.0             0.0   \n",
       "4         0.0              0.0                       0.0             0.0   \n",
       "5         0.0              0.0                       0.0             0.0   \n",
       "6         0.0              0.0                       0.0             0.0   \n",
       "7         0.0              0.0                       0.0             0.0   \n",
       "8         0.0              0.0                       0.0             0.0   \n",
       "9         0.0              0.0                       0.0             0.0   \n",
       "\n",
       "   zorx gamepad  zu belegen  zu perk  zune glengarry  \n",
       "0           0.0         0.0      0.0             0.0  \n",
       "1           0.0         0.0      0.0             0.0  \n",
       "2           0.0         0.0      0.0             0.0  \n",
       "3           0.0         0.0      0.0             0.0  \n",
       "4           0.0         0.0      0.0             0.0  \n",
       "5           0.0         0.0      0.0             0.0  \n",
       "6           0.0         0.0      0.0             0.0  \n",
       "7           0.0         0.0      0.0             0.0  \n",
       "8           0.0         0.0      0.0             0.0  \n",
       "9           0.0         0.0      0.0             0.0  \n",
       "\n",
       "[10 rows x 29293 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X.todense(), columns=tfidf.get_feature_names()).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train-test set\n",
    "Making sure that tweets for the same movie are in the same data set. This is important so we can tally up the classifications for a final prediction later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2883\n",
      "2883\n"
     ]
    }
   ],
   "source": [
    "pre_split = pd.DataFrame(X.todense(), columns=tfidf.get_feature_names()).join(pd.DataFrame(y)).join(df.title)\n",
    "pre_split = pre_split.fillna(0)\n",
    "\n",
    "no_scene_df = pre_split[pre_split.trigger_scene == False]\n",
    "\n",
    "has_scene_df = pre_split[pre_split.trigger_scene == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies with self-harm scenes: 129\n",
      "Number of movies with no self-harm scenes: 83\n",
      "----------------------------------------------------------\n",
      "Number of self-harm movies to put into the train set: 90\n",
      "Number of no self-harm movies to put into the train set: 58\n"
     ]
    }
   ],
   "source": [
    "n_self_harm = len(has_scene_df.title.unique())\n",
    "n_no_self_harm = len(no_scene_df.title.unique())\n",
    "percent_in_train = 0.7\n",
    "\n",
    "print(f'Number of movies with self-harm scenes: {n_self_harm}')\n",
    "print(f'Number of movies with no self-harm scenes: {n_no_self_harm}')\n",
    "\n",
    "print('----------------------------------------------------------')\n",
    "\n",
    "n_self_harm_in_train = round(n_self_harm * percent_in_train)\n",
    "n_no_self_harm_in_train = round(n_no_self_harm * percent_in_train)\n",
    "\n",
    "print(f'Number of self-harm movies to put into the train set: {n_self_harm_in_train}')\n",
    "print(f'Number of no self-harm movies to put into the train set: {n_no_self_harm_in_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and test X sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_has_scene_movie_in_train = has_scene_df.title.unique()[:n_self_harm_in_train][-1]\n",
    "index_of_last_has_scene_movie_in_train = (has_scene_df[has_scene_df.title == last_has_scene_movie_in_train]\n",
    "                                          .index[-1])\n",
    "\n",
    "has_scene_rows_to_include_in_train = has_scene_df.loc[:index_of_last_has_scene_movie_in_train].iloc[:,:-2]\n",
    "has_scene_rows_to_include_in_test = has_scene_df.loc[index_of_last_has_scene_movie_in_train + 1:].iloc[:,:-2]\n",
    "\n",
    "last_no_scene_movie_in_train = no_scene_df.title.unique()[:n_no_self_harm_in_train][-1]\n",
    "index_of_last_no_scene_movie_in_train = (no_scene_df[no_scene_df.title == last_no_scene_movie_in_train]\n",
    "                                          .index[-1])\n",
    "\n",
    "no_scene_rows_to_include_in_train = no_scene_df.loc[:index_of_last_no_scene_movie_in_train].iloc[:,:-2]\n",
    "no_scene_rows_to_include_in_test = no_scene_df.loc[index_of_last_no_scene_movie_in_train + 1:].iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train: 2033\n",
      "Number of rows in test: 850\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.concat([no_scene_rows_to_include_in_train, has_scene_rows_to_include_in_train])\n",
    "X_test = pd.concat([no_scene_rows_to_include_in_test, has_scene_rows_to_include_in_test])\n",
    "\n",
    "print(f'Number of rows in train: {len(X_train)}')\n",
    "print(f'Number of rows in test: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows match up\n"
     ]
    }
   ],
   "source": [
    "if (len(X_train) + len(X_test)) == df.shape[0]:\n",
    "    print('Number of rows match up')\n",
    "else:\n",
    "    print('Number of rows do not match up')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and test y sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_scene_class_rows_to_include_in_train = has_scene_df.loc[:index_of_last_has_scene_movie_in_train].iloc[:,-2]\n",
    "has_scene_class_rows_to_include_in_test = has_scene_df.loc[index_of_last_has_scene_movie_in_train + 1:].iloc[:,-2]\n",
    "\n",
    "no_scene_class_rows_to_include_in_train = no_scene_df.loc[:index_of_last_no_scene_movie_in_train].iloc[:,-2]\n",
    "no_scene_class_rows_to_include_in_test = no_scene_df.loc[index_of_last_no_scene_movie_in_train + 1:].iloc[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train: 2033\n",
      "Number of rows in test: 850\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.concat([no_scene_class_rows_to_include_in_train, has_scene_class_rows_to_include_in_train])\n",
    "y_test = pd.concat([no_scene_class_rows_to_include_in_test, has_scene_class_rows_to_include_in_test])\n",
    "\n",
    "print(f'Number of rows in train: {len(y_train)}')\n",
    "print(f'Number of rows in test: {len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('bool')\n",
    "y_test = y_test.astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows match up\n"
     ]
    }
   ],
   "source": [
    "if (len(y_train) + len(y_test)) == df.shape[0]:\n",
    "    print('Number of rows match up')\n",
    "else:\n",
    "    print('Number of rows do not match up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "We will cross validate with RandomizedSearchCV first to determine hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mz211\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "          estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=123, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=4,\n",
       "          param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001EBD77AAB38>, 'solver': ['newton-cg', 'lbfgs', 'saga', 'liblinear']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=123)\n",
    "parameters = {'C':sp.reciprocal(0.0001, 10000),\n",
    "              'solver':['newton-cg', 'lbfgs', 'saga', 'liblinear']}\n",
    "\n",
    "lr_rs = RandomizedSearchCV(estimator=lr, param_distributions=parameters, n_jobs=4, random_state=123, n_iter=50)\n",
    "lr_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 3.367745609488227, 'solver': 'liblinear'}\n",
      "0.5927201180521396\n"
     ]
    }
   ],
   "source": [
    "print(lr_rs.best_params_)\n",
    "print(lr_rs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearchCV to see if there's a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mz211\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=123, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'solver': ['newton-cg', 'lbfgs', 'saga', 'liblinear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'solver':['newton-cg', 'lbfgs', 'saga', 'liblinear']}\n",
    "\n",
    "lr_gs = GridSearchCV(estimator=lr, param_grid=parameters, n_jobs=4)\n",
    "lr_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'solver': 'newton-cg'}\n",
      "0.5917363502213477\n"
     ]
    }
   ],
   "source": [
    "print(lr_gs.best_params_)\n",
    "print(lr_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Looks like there isn't much of a difference in accuracy.\n",
    "If anything, RandomizedSearchCV is providing slightly better hyperparameters in this case.\n",
    "\n",
    "I'll continue with RandomizedSearch.\n",
    "\n",
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mz211\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "          estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
       "            splitter='best'),\n",
       "          fit_params=None, iid='warn', n_iter=25, n_jobs=4,\n",
       "          param_distributions={'criterion': ['gini', 'entropy'], 'max_depth': [3, 14, 25], 'min_samples_split': [2, 50], 'min_samples_leaf': [1, 2, 3, 4, 5]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=123)\n",
    "parameters = {'criterion':['gini', 'entropy'],\n",
    "              'max_depth':[int(x) for x in np.linspace(3, 25, 3)],\n",
    "              'min_samples_split':[int(x) for x in np.linspace(2,50, 2)],\n",
    "              'min_samples_leaf':[1, 2, 3, 4, 5]}\n",
    "\n",
    "dt_rs = RandomizedSearchCV(estimator=dt, param_distributions=parameters, n_jobs=4, n_iter=25)\n",
    "dt_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 25, 'criterion': 'entropy'}\n",
      "0.5602557796360059\n"
     ]
    }
   ],
   "source": [
    "print(dt_rs.best_params_)\n",
    "print(dt_rs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mz211\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=123, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=4,\n",
       "          param_distributions={'n_estimators': [5, 16, 27, 38, 50], 'criterion': ['gini', 'entropy'], 'max_depth': [3, 16, 30], 'min_samples_split': [2, 20], 'min_samples_leaf': [1]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=123)\n",
    "parameters = {'n_estimators':[int(x) for x in np.linspace(5, 50, 5)],\n",
    "              'criterion':['gini', 'entropy'],\n",
    "              'max_depth':[int(x) for x in np.linspace(3, 30, 3)],\n",
    "              'min_samples_split':[int(x) for x in np.linspace(2, 20, 2)],\n",
    "              'min_samples_leaf':[int(x) for x in np.linspace(1, 3, 1)]}\n",
    "\n",
    "rf_rs = RandomizedSearchCV(estimator=rf, param_distributions=parameters, n_jobs=4, n_iter=50)\n",
    "rf_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30, 'criterion': 'entropy'}\n",
      "0.5622233152975897\n"
     ]
    }
   ],
   "source": [
    "print(rf_rs.best_params_)\n",
    "print(rf_rs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mz211\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "knneighbors = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':[3, 5, 7, 9, 13],\n",
    "              'weights':['uniform', 'distance'],\n",
    "              'algorithm':['ball_tree', 'kd_tree', 'brute'],\n",
    "              'p':[1, 2],\n",
    "              'metric':['minkowski', 'euclidean', 'manhattan']}\n",
    "\n",
    "knneighbors_rs = RandomizedSearchCV(estimator=knneighbors, param_distributions=parameters, n_jobs=4, n_iter=10, verbose=10)\n",
    "knneighbors_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knneighbors_rs.best_params_)\n",
    "print(knneighbors_rs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = xgb.sklearn.XGBClassifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
