{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from time import sleep\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import unicodedata\n",
    "import json\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "import pprint as pprint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import scipy.stats as sp\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_new_decision_threshold(probability, new_threshold):\n",
    "    if probability > new_threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def custom_train_test_split(df, vectorizer, X, y):\n",
    "    '''Takes in original dataframe, vectorizer, sparse matrix of X values, and y values in a Series. \n",
    "        Returns two dataframes for each class (has_scene, no_scene), \n",
    "        train and test for X and y (X_train, X_test, y_train, y_test), \n",
    "        and the train and test dataframes for predictions (train, test).'''\n",
    "    pre_split = pd.DataFrame(X.todense(), \n",
    "                             columns=bag_of_words.get_feature_names()).join(pd.DataFrame(y)).join(df.title, \n",
    "                                                                                                  rsuffix='_of_movie')\n",
    "    pre_split = pre_split.fillna(0)\n",
    "    no_scene_df = pre_split[pre_split.trigger_scene == False]\n",
    "    has_scene_df = pre_split[pre_split.trigger_scene == True]\n",
    "    \n",
    "    n_self_harm = len(has_scene_df.title_of_movie.unique())\n",
    "    n_no_self_harm = len(no_scene_df.title_of_movie.unique())\n",
    "    percent_in_train = 0.7\n",
    "\n",
    "    print(f'Number of movies with self-harm scenes: {n_self_harm}')\n",
    "    print(f'Number of movies with no self-harm scenes: {n_no_self_harm}')\n",
    "\n",
    "    print('----------------------------------------------------------')\n",
    "\n",
    "    n_self_harm_in_train = round(n_self_harm * percent_in_train)\n",
    "    n_no_self_harm_in_train = round(n_no_self_harm * percent_in_train)\n",
    "\n",
    "    print(f'Number of self-harm movies to put into the train set: {n_self_harm_in_train}')\n",
    "    print(f'Number of no self-harm movies to put into the train set: {n_no_self_harm_in_train}')\n",
    "    \n",
    "    # X variables\n",
    "    \n",
    "    last_has_scene_movie_in_train = has_scene_df.title_of_movie.unique()[:n_self_harm_in_train][-1]\n",
    "    index_of_last_has_scene_movie_in_train = (has_scene_df[has_scene_df.title_of_movie == last_has_scene_movie_in_train]\n",
    "                                              .index[-1])\n",
    "\n",
    "    has_scene_rows_to_include_in_train = has_scene_df.loc[:index_of_last_has_scene_movie_in_train].iloc[:,:-2]\n",
    "    has_scene_rows_to_include_in_test = has_scene_df.loc[index_of_last_has_scene_movie_in_train + 1:].iloc[:,:-2]\n",
    "\n",
    "    last_no_scene_movie_in_train = no_scene_df.title_of_movie.unique()[:n_no_self_harm_in_train][-1]\n",
    "    index_of_last_no_scene_movie_in_train = (no_scene_df[no_scene_df.title_of_movie == last_no_scene_movie_in_train]\n",
    "                                              .index[-1])\n",
    "\n",
    "    no_scene_rows_to_include_in_train = no_scene_df.loc[:index_of_last_no_scene_movie_in_train].iloc[:,:-2]\n",
    "    no_scene_rows_to_include_in_test = no_scene_df.loc[index_of_last_no_scene_movie_in_train + 1:].iloc[:,:-2]\n",
    "    \n",
    "    X_train = pd.concat([no_scene_rows_to_include_in_train, has_scene_rows_to_include_in_train])\n",
    "    X_test = pd.concat([no_scene_rows_to_include_in_test, has_scene_rows_to_include_in_test])\n",
    "\n",
    "    print(f'Number of rows in train: {len(X_train)}')\n",
    "    print(f'Number of rows in test: {len(X_test)}')\n",
    "    \n",
    "    if (len(X_train) + len(X_test)) == df.shape[0]:\n",
    "        print('Number of rows match up')\n",
    "    else:\n",
    "        print('Number of rows do not match up')\n",
    "    \n",
    "    # y variable\n",
    "    \n",
    "    has_scene_class_rows_to_include_in_train = has_scene_df.loc[:index_of_last_has_scene_movie_in_train].iloc[:,-2]\n",
    "    has_scene_class_rows_to_include_in_test = has_scene_df.loc[index_of_last_has_scene_movie_in_train + 1:].iloc[:,-2]\n",
    "\n",
    "    no_scene_class_rows_to_include_in_train = no_scene_df.loc[:index_of_last_no_scene_movie_in_train].iloc[:,-2]\n",
    "    no_scene_class_rows_to_include_in_test = no_scene_df.loc[index_of_last_no_scene_movie_in_train + 1:].iloc[:,-2]\n",
    "    \n",
    "    y_train = pd.concat([no_scene_class_rows_to_include_in_train, has_scene_class_rows_to_include_in_train])\n",
    "    y_test = pd.concat([no_scene_class_rows_to_include_in_test, has_scene_class_rows_to_include_in_test])\n",
    "\n",
    "    print(f'Number of rows in train: {len(y_train)}')\n",
    "    print(f'Number of rows in test: {len(y_test)}')\n",
    "    \n",
    "    y_train = y_train.astype('bool')\n",
    "    y_test = y_test.astype('bool')\n",
    "    \n",
    "    if (len(y_train) + len(y_test)) == df.shape[0]:\n",
    "        print('Number of rows match up')\n",
    "    else:\n",
    "        print('Number of rows do not match up')\n",
    "        \n",
    "    # train and test prediction dataframes\n",
    "        \n",
    "    train = pd.DataFrame(dict(actual=y_train))\n",
    "    test = pd.DataFrame(dict(actual=y_test))\n",
    "    \n",
    "    return no_scene_df, has_scene_df, X_train, X_test, y_train, y_test, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tweet</th>\n",
       "      <th>trigger_scene</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>lemmatized_no_stopwords</th>\n",
       "      <th>stemmed_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spiderman_far_from_home</td>\n",
       "      <td>spiderman far from home had a joke where peter...</td>\n",
       "      <td>False</td>\n",
       "      <td>spiderman far from home had a joke where peter...</td>\n",
       "      <td>spiderman far from home had a joke where peter...</td>\n",
       "      <td>spiderman far from home had a joke where peter...</td>\n",
       "      <td>joke peter mistake acdc led zeppelin triggered...</td>\n",
       "      <td>joke peter mistak acdc led zeppelin ptsd becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spiderman_far_from_home</td>\n",
       "      <td>Trigger warning for all photographers before s...</td>\n",
       "      <td>False</td>\n",
       "      <td>trigger warning for all photographers before s...</td>\n",
       "      <td>trigger warn for all photograph befor see spid...</td>\n",
       "      <td>trigger warning for all photographer before se...</td>\n",
       "      <td>warning photographer seeing</td>\n",
       "      <td>warn photograph befor see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spiderman_far_from_home</td>\n",
       "      <td>so i just finished watching spiderman far from...</td>\n",
       "      <td>False</td>\n",
       "      <td>so i just finished watching spiderman far from...</td>\n",
       "      <td>so i just finish watch spiderman far from home...</td>\n",
       "      <td>so i just finished watching spiderman far from...</td>\n",
       "      <td>finished loved im car hearing fever got confus...</td>\n",
       "      <td>finish watch im car hear fever got confus bc t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spiderman_far_from_home</td>\n",
       "      <td>Spiderman: Far From Home was a gaslighting tri...</td>\n",
       "      <td>False</td>\n",
       "      <td>spiderman far from home was a gaslighting trig...</td>\n",
       "      <td>spiderman far from home wa a gaslight trigger ...</td>\n",
       "      <td>spiderman far from home wa a gaslighting trigg...</td>\n",
       "      <td>wa gaslighting half aint nobody warned</td>\n",
       "      <td>wa gaslight half aint nobodi warn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spiderman_far_from_home</td>\n",
       "      <td>it trigger me every time there's a spiderman f...</td>\n",
       "      <td>False</td>\n",
       "      <td>it trigger me every time theres a spiderman fa...</td>\n",
       "      <td>it trigger me everi time there a spiderman far...</td>\n",
       "      <td>it trigger me every time there a spiderman far...</td>\n",
       "      <td>every trailer tv start nowhere playing tom hol...</td>\n",
       "      <td>everi trailer tv start nowher tom holland cri ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                              tweet  \\\n",
       "0  spiderman_far_from_home  spiderman far from home had a joke where peter...   \n",
       "1  spiderman_far_from_home  Trigger warning for all photographers before s...   \n",
       "2  spiderman_far_from_home  so i just finished watching spiderman far from...   \n",
       "3  spiderman_far_from_home  Spiderman: Far From Home was a gaslighting tri...   \n",
       "4  spiderman_far_from_home  it trigger me every time there's a spiderman f...   \n",
       "\n",
       "   trigger_scene                                       cleaned_text  \\\n",
       "0          False  spiderman far from home had a joke where peter...   \n",
       "1          False  trigger warning for all photographers before s...   \n",
       "2          False  so i just finished watching spiderman far from...   \n",
       "3          False  spiderman far from home was a gaslighting trig...   \n",
       "4          False  it trigger me every time theres a spiderman fa...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0  spiderman far from home had a joke where peter...   \n",
       "1  trigger warn for all photograph befor see spid...   \n",
       "2  so i just finish watch spiderman far from home...   \n",
       "3  spiderman far from home wa a gaslight trigger ...   \n",
       "4  it trigger me everi time there a spiderman far...   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0  spiderman far from home had a joke where peter...   \n",
       "1  trigger warning for all photographer before se...   \n",
       "2  so i just finished watching spiderman far from...   \n",
       "3  spiderman far from home wa a gaslighting trigg...   \n",
       "4  it trigger me every time there a spiderman far...   \n",
       "\n",
       "                             lemmatized_no_stopwords  \\\n",
       "0  joke peter mistake acdc led zeppelin triggered...   \n",
       "1                        warning photographer seeing   \n",
       "2  finished loved im car hearing fever got confus...   \n",
       "3             wa gaslighting half aint nobody warned   \n",
       "4  every trailer tv start nowhere playing tom hol...   \n",
       "\n",
       "                                stemmed_no_stopwords  \n",
       "0  joke peter mistak acdc led zeppelin ptsd becau...  \n",
       "1                          warn photograph befor see  \n",
       "2  finish watch im car hear fever got confus bc t...  \n",
       "3                  wa gaslight half aint nobodi warn  \n",
       "4  everi trailer tv start nowher tom holland cri ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('trigger_warning_tweets.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                      0\n",
       "tweet                      1\n",
       "trigger_scene              0\n",
       "cleaned_text               3\n",
       "stemmed_text               3\n",
       "lemmatized_text            3\n",
       "lemmatized_no_stopwords    7\n",
       "stemmed_no_stopwords       5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                      0\n",
       "tweet                      0\n",
       "trigger_scene              0\n",
       "cleaned_text               0\n",
       "stemmed_text               0\n",
       "lemmatized_text            0\n",
       "lemmatized_no_stopwords    0\n",
       "stemmed_no_stopwords       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = CountVectorizer()\n",
    "X = bag_of_words.fit_transform(df.lemmatized_no_stopwords)\n",
    "y = df.trigger_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies with self-harm scenes: 129\n",
      "Number of movies with no self-harm scenes: 83\n",
      "----------------------------------------------------------\n",
      "Number of self-harm movies to put into the train set: 90\n",
      "Number of no self-harm movies to put into the train set: 58\n",
      "Number of rows in train: 2033\n",
      "Number of rows in test: 850\n",
      "Number of rows match up\n",
      "Number of rows in train: 2033\n",
      "Number of rows in test: 850\n",
      "Number of rows match up\n"
     ]
    }
   ],
   "source": [
    "has_scene_df, no_scene_df, X_train, X_test, y_train, y_test, train, test = custom_train_test_split(df, bag_of_words, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mz211\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "          estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=123, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=4,\n",
       "          param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001AD19DF87F0>, 'solver': ['newton-cg', 'lbfgs', 'saga', 'liblinear']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=123)\n",
    "parameters = {'C':sp.reciprocal(0.0001, 10000),\n",
    "              'solver':['newton-cg', 'lbfgs', 'saga', 'liblinear']}\n",
    "\n",
    "lr_rs = RandomizedSearchCV(estimator=lr, param_distributions=parameters, n_jobs=4)\n",
    "lr_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.010532190137107452, 'solver': 'newton-cg'}\n",
      "0.5656665027053616\n"
     ]
    }
   ],
   "source": [
    "print(lr_rs.best_params_)\n",
    "print(lr_rs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mz211\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "          estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
       "            splitter='best'),\n",
       "          fit_params=None, iid='warn', n_iter=25, n_jobs=4,\n",
       "          param_distributions={'criterion': ['gini', 'entropy'], 'max_depth': [3, 14, 25], 'min_samples_split': [2, 50], 'min_samples_leaf': [1, 2, 3, 4, 5]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=123)\n",
    "parameters = {'criterion':['gini', 'entropy'],\n",
    "              'max_depth':[int(x) for x in np.linspace(3, 25, 3)],\n",
    "              'min_samples_split':[int(x) for x in np.linspace(2,50, 2)],\n",
    "              'min_samples_leaf':[1, 2, 3, 4, 5]}\n",
    "\n",
    "dt_rs = RandomizedSearchCV(estimator=dt, param_distributions=parameters, n_jobs=4, n_iter=25)\n",
    "dt_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 25, 'criterion': 'entropy'}\n",
      "0.5764879488440728\n"
     ]
    }
   ],
   "source": [
    "print(dt_rs.best_params_)\n",
    "print(dt_rs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mz211\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=123)\n",
    "parameters = {'n_estimators':[int(x) for x in np.linspace(5, 50, 5)],\n",
    "              'criterion':['gini', 'entropy'],\n",
    "              'max_depth':[int(x) for x in np.linspace(3, 30, 3)],\n",
    "              'min_samples_split':[int(x) for x in np.linspace(2, 20, 2)],\n",
    "              'min_samples_leaf':[int(x) for x in np.linspace(1, 3, 1)]}\n",
    "\n",
    "rf_rs = RandomizedSearchCV(estimator=rf, param_distributions=parameters, n_jobs=4, n_iter=50)\n",
    "rf_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_rs.best_params_)\n",
    "print(rf_rs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
